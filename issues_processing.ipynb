{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Issues using Gemma7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import tiktoken\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/prediction_data/issues.json') as f:\n",
    "    issues_data = [json.loads(line) for line in f]\n",
    "#issues_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 6000\n",
    "separator = '\\n'\n",
    "backup_separators = [\".\", \" \"]\n",
    "tokenizer = partial(tiktoken.get_encoding(\"cl100k_base\").encode, allowed_special=\"all\")\n",
    "\n",
    "def txt_splitter(text):\n",
    "    text_splitter = TokenTextSplitter(separator=separator,\n",
    "                                        chunk_size=chunk_size,\n",
    "                                        backup_separators=backup_separators,\n",
    "                                        tokenizer=tokenizer)\n",
    "    # print(len(tokenizer(text))))  ### Check token size \n",
    "    if len(tokenizer(text)) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for issues in issues_data:\n",
    "    issues['issues'] = txt_splitter(issues['issues'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def generate_summary_template(context, prev_summary=''):\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "    You are a Singapore Lawyer. \\n\n",
    "    summarise the main issues of the legal judgment below in 1500 words:\\n\n",
    "    {prev_summary}\\n\n",
    "    {context}.\n",
    "    \"\"\"\n",
    "    return prompt_template\n",
    "\n",
    "def generate_final_template(context):\n",
    "    prompt_template = f\"\"\"\n",
    "    {context}.\\n\n",
    "    summarise the legal issues above into sentences separated by full-stop. DO NOT give any headers.\n",
    "\n",
    "    EXAMPLE: (if there are 3 issues)\n",
    "    Issue 1. Issue 2. Issue 3.\n",
    "    \"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "json_path = 'processed_issues.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "checkpoint = 0\n",
    "for issues in issues_data:\n",
    "    if len(issues) == 3:\n",
    "        continue\n",
    "    \n",
    "    prev_summary = ''\n",
    "    checkpoint += 1\n",
    "    for chunk in issues['issues']:\n",
    "        context = generate_summary_template(chunk, prev_summary)\n",
    "        response = ollama.generate(model='gemma', prompt=str(context), stream=False)\n",
    "        prev_summary = response['response']\n",
    "    \n",
    "    print(prev_summary)\n",
    "    overall_summary = generate_final_template(prev_summary)\n",
    "    response = ollama.generate(model='gemma', prompt=str(overall_summary), stream=False)\n",
    "    final_summary = response['response']\n",
    "    \n",
    "    issues['summarised issues'] = final_summary.split('.')\n",
    "\n",
    "    \n",
    "    if checkpoint == 500:\n",
    "        with open(json_path, 'w') as jf:\n",
    "            json.dump(issues_data, jf, indent=4)\n",
    "        checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.9)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'issues_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m issues \u001b[38;5;129;01min\u001b[39;00m \u001b[43missues_data\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(issues[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummarised issues\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'issues_data' is not defined"
     ]
    }
   ],
   "source": [
    "for issues in issues_data:\n",
    "    print(issues['summarised issues'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
