{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from json import loads, dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Interceptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENT = '\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"'\n",
    "SEC_CH_UA = '\\\"Google Chrome\\\";v=\\\"123\\\", \\\"Not:A-Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"123\\\"'\n",
    "REFERER = \"https://www.google.com\"\n",
    "\n",
    "def interceptor(request):\n",
    "    del request.header[\"user-agent\"]\n",
    "    request.header[\"user-agent\"] = USER_AGENT\n",
    "    request.header[\"sec-ch-ua\"] = SEC_CH_UA\n",
    "    request.header[\"referer\"] = REFERER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompose function to find corams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose(text):\n",
    "    if \"\\n\" in text:\n",
    "        return text.split(\"\\n\")[1].split(\" \")\n",
    "    return text.split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract coram names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_names(text):\n",
    "    remove_words_containing = ('CJ', 'AG', 'J', 'DCJ', 'JA', 'AR', 'JC', 'SAR', 'JCA', 'SJ', 'JAD', 'and',\n",
    "                               'CJ,', 'AG,', 'J,', 'DCJ,', 'JA,', 'AR,', 'JC,', 'SAR,', 'JCA,', 'SJ,', 'JAD,')\n",
    "    name = \"\"\n",
    "    name_list = []\n",
    "\n",
    "    for word in text:\n",
    "        if word not in remove_words_containing:\n",
    "            name += word + \" \"\n",
    "        else:\n",
    "            if len(name):\n",
    "                name_list.append(name.strip())\n",
    "                name = \"\"\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coram Extraction (2000 - 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coram Extraction (2000 to 2015)\n",
    "# # Creating the webdriver\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.request_interceptor = interceptor\n",
    "# driver.maximize_window()\n",
    "\n",
    "# base_url = \"https://www.elitigation.sg/gdviewer/s/{year}_{court}_{case_id}\"\n",
    "\n",
    "# years = range(2000, 2016)\n",
    "# courts = ['SGHC', 'SGCA']\n",
    "# case_ids = range(1, 430)\n",
    "\n",
    "# for year in years:\n",
    "#     for court in courts:\n",
    "#         for case_id in case_ids:\n",
    "#             case_url = base_url.format(year=year, court=court, case_id=case_id)\n",
    "#             driver.get(case_url)\n",
    "#             containers = driver.find_elements(By.XPATH, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coram Extraction (2016 to 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.request_interceptor = interceptor\n",
    "driver.maximize_window()\n",
    "\n",
    "base_url = \"https://www.elitigation.sg/gdviewer/s/{year}_{court}_{case_id}\"\n",
    "\n",
    "years = range(2016, 2024)\n",
    "courts = ['SGHC', 'SGCA']\n",
    "case_ids = range(1, 430)\n",
    "SPECIAL_CASES = (31, 88)\n",
    "\n",
    "temp_df = pd.DataFrame(columns=[\"casename\", \"coram\"])\n",
    "counter = 0\n",
    "for year in years:\n",
    "    for court in courts:\n",
    "        for case_id in case_ids:\n",
    "            case_url = base_url.format(year=year, court=court, case_id=case_id)\n",
    "            driver.get(case_url)\n",
    "            containers = driver.find_elements(By.CSS_SELECTOR, 'div.HN-Coram.text-left')\n",
    "            if not containers:\n",
    "                containers = driver.find_elements(By.CSS_SELECTOR, 'div.txt-body.text-left')\n",
    "            if not containers:\n",
    "                containers = driver.find_elements(By.CSS_SELECTOR, 'div.Judg-Date-Reserved.text-left')\n",
    "            coram_list_unprocessed = list(map(lambda x: x.text, containers))\n",
    "            print(coram_list_unprocessed)\n",
    "            if len(coram_list_unprocessed) == 1 or case_id in SPECIAL_CASES:   \n",
    "                coram_list_processed = coram_list_unprocessed[0].split(\"\\n\")[1] # 2nd element contains the coram\n",
    "            else:\n",
    "                coram_list_processed = coram_list_unprocessed[1]\n",
    "            # print(coram_list_processed)\n",
    "            # print(decompose(coram_list_processed))\n",
    "            print(counter, extract_names(decompose(coram_list_processed)))\n",
    "            temp_df.loc[len(temp_df.index)] = [f\"{year}_{court}_{case_id}\", extract_names(decompose(coram_list_processed))]\n",
    "            counter += 1\n",
    "            sec = random.randint(1, 10)\n",
    "            time.sleep(sec)\n",
    "        #     break\n",
    "        # break\n",
    "\n",
    "        # Save to json\n",
    "        file = f\"{year}_{court}_coram.json\"\n",
    "        temp_df.to_json(file, orient=\"records\", lines=True)\n",
    "\n",
    "driver.quit()\n",
    " \n",
    "temp_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
